"""
Streamlit App c·∫£i ti·∫øn cho Predictive Maintenance Data Analysis
T√≠ch h·ª£p t·ª´ c√°c notebook ƒë√£ upload
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from io import StringIO, BytesIO
import base64
import warnings
warnings.filterwarnings('ignore')

# Import improved modules
from improved_cleaner import ImprovedDataCleaner, clean_maintenance_data
from improved_eda import ImprovedEDAAnalyzer, analyze_maintenance_data

# Page configuration
st.set_page_config(
    page_title="Predictive Maintenance Data Analyzer",
    page_icon="üîß",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2e3440;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeeba;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def create_download_link(df, filename="cleaned_data.csv"):
    """T·∫°o link download cho DataFrame"""
    csv_buffer = StringIO()
    df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
    csv_data = csv_buffer.getvalue()
    
    b64 = base64.b64encode(csv_data.encode('utf-8-sig')).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}" class="download-link">üì• T·∫£i xu·ªëng {filename}</a>'
    return href

def main():
    st.markdown('<h1 class="main-header">üîß Predictive Maintenance Data Analyzer</h1>', unsafe_allow_html=True)
    
    # Sidebar navigation
    st.sidebar.title("ƒêi·ªÅu h∆∞·ªõng")
    page = st.sidebar.selectbox(
        "Ch·ªçn trang:",
        ["üì§ T·∫£i l√™n & L√†m s·∫°ch d·ªØ li·ªáu", "üìä Ph√¢n t√≠ch d·ªØ li·ªáu kh√°m ph√°", "üéØ Ph√¢n t√≠ch Machine Failure", "üìà Ph√¢n t√≠ch n√¢ng cao"]
    )
    
    # Initialize session state
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'cleaned_data' not in st.session_state:
        st.session_state.cleaned_data = None
    
    # Route to different pages
    if page == "üì§ T·∫£i l√™n & L√†m s·∫°ch d·ªØ li·ªáu":
        upload_and_cleaning_page()
    elif page == "üìä Ph√¢n t√≠ch d·ªØ li·ªáu kh√°m ph√°":
        eda_page()
    elif page == "üéØ Ph√¢n t√≠ch Machine Failure":
        failure_analysis_page()
    elif page == "üìà Ph√¢n t√≠ch n√¢ng cao":
        advanced_analysis_page()

def upload_and_cleaning_page():
    st.markdown('<h2 class="section-header">T·∫£i l√™n & L√†m s·∫°ch d·ªØ li·ªáu</h2>', unsafe_allow_html=True)
    
    st.markdown("""
    **C√°c lo·∫°i file ƒë∆∞·ª£c h·ªó tr·ª£:**
    - **dirty_sample_500.csv**: D·ªØ li·ªáu b·∫©n m·∫´u 500 d√≤ng (cho EDA)
    - **dirty_sample_500_worse_plus.csv**: D·ªØ li·ªáu b·∫©n n·∫∑ng (test l√†m s·∫°ch)
    - **ai4i2020.csv**: Dataset g·ªëc Predictive Maintenance
    - **sample_dirty_data.csv**: File m·∫´u ƒë·ªÉ test ngay
    
    *Ho·∫∑c t·∫£i file CSV kh√°c t∆∞∆°ng t·ª± ƒë·ªÉ ph√¢n t√≠ch*
    """)
    
    # File upload
    uploaded_file = st.file_uploader(
        "Ch·ªçn file CSV",
        type="csv",
        help="T·∫£i l√™n d·ªØ li·ªáu predictive maintenance c·ªßa b·∫°n"
    )
    
    if uploaded_file is not None:
        try:
            # Load data
            df = pd.read_csv(uploaded_file)
            st.session_state.data = df
            
            st.success(f"‚úÖ T·∫£i file th√†nh c√¥ng! K√≠ch th∆∞·ªõc: {df.shape[0]} h√†ng x {df.shape[1]} c·ªôt")
            
            # Display basic info
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("S·ªë h√†ng", df.shape[0])
            with col2:
                st.metric("S·ªë c·ªôt", df.shape[1])
            with col3:
                st.metric("Gi√° tr·ªã thi·∫øu", df.isnull().sum().sum())
            
            # Show data preview
            st.markdown('<h3 class="section-header">Xem tr∆∞·ªõc d·ªØ li·ªáu</h3>', unsafe_allow_html=True)
            st.dataframe(df.head(10), use_container_width=True)
            
            # Data info
            st.markdown('<h3 class="section-header">Th√¥ng tin d·ªØ li·ªáu</h3>', unsafe_allow_html=True)
            
            # Missing data chart
            missing_data = df.isnull().sum()
            missing_data = missing_data[missing_data > 0].sort_values(ascending=False)
            
            if not missing_data.empty:
                fig = px.bar(
                    x=missing_data.index,
                    y=missing_data.values,
                    title="S·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu theo c·ªôt",
                    labels={'x': 'C·ªôt', 'y': 'S·ªë l∆∞·ª£ng thi·∫øu'}
                )
                fig.update_layout(showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("‚úÖ Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu n√†o!")
            
            # Clean data button
            if st.button("üßπ L√†m s·∫°ch d·ªØ li·ªáu", type="primary"):
                with st.spinner("ƒêang l√†m s·∫°ch d·ªØ li·ªáu..."):
                    cleaned_df, cleaning_summary = clean_maintenance_data(df)
                    st.session_state.cleaned_data = cleaned_df
                    
                    st.success("‚úÖ L√†m s·∫°ch d·ªØ li·ªáu ho√†n th√†nh!")
                    
                    # Show results comparison
                    col1, col2 = st.columns(2)
                    with col1:
                        st.subheader("D·ªØ li·ªáu g·ªëc")
                        st.metric("H√†ng", df.shape[0])
                        st.metric("C·ªôt", df.shape[1])
                        st.metric("Gi√° tr·ªã thi·∫øu", df.isnull().sum().sum())
                        st.metric("Tr√πng l·∫∑p", df.duplicated().sum())
                    
                    with col2:
                        st.subheader("D·ªØ li·ªáu sau l√†m s·∫°ch")
                        st.metric("H√†ng", cleaned_df.shape[0])
                        st.metric("C·ªôt", cleaned_df.shape[1])
                        st.metric("Gi√° tr·ªã thi·∫øu", cleaned_df.isnull().sum().sum())
                        st.metric("Tr√πng l·∫∑p", cleaned_df.duplicated().sum())
                    
                    # Show cleaning log
                    st.subheader("C√°c b∆∞·ªõc l√†m s·∫°ch ƒë√£ th·ª±c hi·ªán:")
                    for step in cleaning_summary:
                        st.write(f"‚úì {step}")
                    
                    # Download cleaned data
                    st.markdown(
                        create_download_link(cleaned_df, "cleaned_data.csv"),
                        unsafe_allow_html=True
                    )
                    
                    # Show cleaned data preview
                    st.markdown('<h3 class="section-header">D·ªØ li·ªáu sau khi l√†m s·∫°ch</h3>', unsafe_allow_html=True)
                    st.dataframe(cleaned_df.head(10), use_container_width=True)
        
        except Exception as e:
            st.error(f"‚ùå L·ªói khi t·∫£i file: {str(e)}")

def eda_page():
    st.markdown('<h2 class="section-header">Ph√¢n t√≠ch d·ªØ li·ªáu kh√°m ph√° (EDA)</h2>', unsafe_allow_html=True)
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i l√™n d·ªØ li·ªáu tr∆∞·ªõc ·ªü trang 'T·∫£i l√™n & L√†m s·∫°ch d·ªØ li·ªáu'.")
        return
    
    # Choose dataset
    data_options = ["D·ªØ li·ªáu g·ªëc"]
    if st.session_state.cleaned_data is not None:
        data_options.append("D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch")
    
    data_choice = st.radio("Ch·ªçn d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch:", data_options)
    
    df = st.session_state.cleaned_data if data_choice == "D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch" else st.session_state.data
    
    # Perform EDA analysis
    with st.spinner("ƒêang ph√¢n t√≠ch d·ªØ li·ªáu..."):
        eda_report = analyze_maintenance_data(df)
    
    # Display basic info
    st.markdown('<h3 class="section-header">Th√¥ng tin t·ªïng quan</h3>', unsafe_allow_html=True)
    
    basic_info = eda_report['basic_info']
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("T·ªïng s·ªë h√†ng", basic_info['shape'][0])
    with col2:
        st.metric("T·ªïng s·ªë c·ªôt", basic_info['shape'][1])
    with col3:
        st.metric("B·ªô nh·ªõ (MB)", basic_info['memory_usage_mb'])
    with col4:
        missing_total = sum(basic_info['missing_values'].values())
        st.metric("T·ªïng gi√° tr·ªã thi·∫øu", missing_total)
    
    # Data quality issues
    if eda_report['data_quality_issues']:
        st.markdown('<h3 class="section-header">V·∫•n ƒë·ªÅ ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu</h3>', unsafe_allow_html=True)
        for issue in eda_report['data_quality_issues']:
            st.warning(f"‚ö†Ô∏è {issue}")
    
    # Numeric analysis
    if eda_report['numeric_analysis']:
        st.markdown('<h3 class="section-header">Ph√¢n t√≠ch c√°c c·ªôt s·ªë</h3>', unsafe_allow_html=True)
        
        numeric_df = pd.DataFrame(eda_report['numeric_analysis']).T
        st.dataframe(numeric_df, use_container_width=True)
        
        # Distribution plots
        st.subheader("Ph√¢n ph·ªëi d·ªØ li·ªáu")
        plot_data = eda_report['plot_data']
        
        for col_name, col_data in plot_data.items():
            if col_data['data']:
                fig = make_subplots(
                    rows=1, cols=2,
                    subplot_titles=[f'{col_name} - Box Plot', f'{col_name} - Histogram']
                )
                
                # Box plot
                fig.add_trace(
                    go.Box(y=col_data['data'], name=col_name, showlegend=False),
                    row=1, col=1
                )
                
                # Histogram
                fig.add_trace(
                    go.Histogram(x=col_data['data'], name=col_name, showlegend=False, nbinsx=30),
                    row=1, col=2
                )
                
                fig.update_layout(height=400, title_text=f"Ph√¢n t√≠ch {col_name}")
                st.plotly_chart(fig, use_container_width=True)
    
    # Type column analysis
    if eda_report['type_analysis']:
        st.markdown('<h3 class="section-header">Ph√¢n t√≠ch c·ªôt Type</h3>', unsafe_allow_html=True)
        
        type_analysis = eda_report['type_analysis']
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**C√°c gi√° tr·ªã unique:**")
            st.write(type_analysis['unique_values'])
            
            if type_analysis['inconsistent_values']:
                st.warning(f"‚ö†Ô∏è Gi√° tr·ªã kh√¥ng nh·∫•t qu√°n: {type_analysis['inconsistent_values']}")
        
        with col2:
            st.write("**S·ªë l∆∞·ª£ng theo t·ª´ng lo·∫°i:**")
            items_list = list(type_analysis['value_counts'].items())
            value_counts_df = pd.DataFrame(items_list, columns=['Type', 'S·ªë l∆∞·ª£ng'])
            st.dataframe(value_counts_df)
            
            # Type distribution chart
            fig = px.pie(
                values=list(type_analysis['value_counts'].values()),
                names=list(type_analysis['value_counts'].keys()),
                title="Ph√¢n ph·ªëi Type"
            )
            st.plotly_chart(fig)
    
    # Correlation analysis
    if eda_report['correlation_analysis']:
        st.markdown('<h3 class="section-header">Ph√¢n t√≠ch t∆∞∆°ng quan</h3>', unsafe_allow_html=True)
        
        corr_analysis = eda_report['correlation_analysis']
        
        # Show top correlations
        if corr_analysis['top_correlations']:
            st.subheader("Top 10 t∆∞∆°ng quan m·∫°nh nh·∫•t")
            corr_df = pd.DataFrame(corr_analysis['top_correlations'])
            st.dataframe(corr_df, use_container_width=True)
        
        # Strong correlations
        if corr_analysis['strong_correlations']:
            st.subheader("T∆∞∆°ng quan m·∫°nh (|r| > 0.7)")
            strong_corr_df = pd.DataFrame(corr_analysis['strong_correlations'])
            st.dataframe(strong_corr_df, use_container_width=True)

def failure_analysis_page():
    st.markdown('<h2 class="section-header">Ph√¢n t√≠ch Machine Failure</h2>', unsafe_allow_html=True)
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i l√™n d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    
    # Choose dataset
    data_options = ["D·ªØ li·ªáu g·ªëc"]
    if st.session_state.cleaned_data is not None:
        data_options.append("D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch")
    
    data_choice = st.radio("Ch·ªçn d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch:", data_options)
    df = st.session_state.cleaned_data if data_choice == "D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch" else st.session_state.data
    
    # Get failure analysis
    eda_report = analyze_maintenance_data(df)
    failure_analysis = eda_report['failure_analysis']
    
    if not failure_analysis:
        st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt failure trong d·ªØ li·ªáu.")
        return
    
    # Show failure summary
    if 'summary' in failure_analysis:
        summary = failure_analysis['summary']
        
        st.markdown('<h3 class="section-header">T·ªïng quan Machine Failure</h3>', unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("T·ªïng m·∫´u", summary['total_samples'])
        with col2:
            st.metric("T·ªïng failure", summary['total_failures'])
        with col3:
            st.metric("T·ªâ l·ªá failure", f"{summary['failure_percentage']:.2f}%")
        with col4:
            normal_samples = summary['total_samples'] - summary['total_failures']
            st.metric("M·∫´u b√¨nh th∆∞·ªùng", normal_samples)
        
        # Failure distribution pie chart
        fig = px.pie(
            values=[summary['total_failures'], normal_samples],
            names=['Machine Failure', 'Normal Operation'],
            title="Ph√¢n ph·ªëi Machine Failure vs Normal"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Individual failure type analysis
    st.markdown('<h3 class="section-header">Ph√¢n t√≠ch t·ª´ng lo·∫°i failure</h3>', unsafe_allow_html=True)
    
    failure_types = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']
    available_types = [f for f in failure_types if f in failure_analysis]
    
    if available_types:
        # Create subplot for failure types
        cols_per_row = 3
        rows = (len(available_types) + cols_per_row - 1) // cols_per_row
        
        fig = make_subplots(
            rows=rows, cols=cols_per_row,
            subplot_titles=available_types,
            specs=[[{"type": "pie"}] * cols_per_row for _ in range(rows)]
        )
        
        for i, failure_type in enumerate(available_types):
            row = i // cols_per_row + 1
            col = i % cols_per_row + 1
            
            if failure_type in failure_analysis:
                failure_data = failure_analysis[failure_type]
                if 'value_counts' in failure_data:
                    values = list(failure_data['value_counts'].values())
                    labels = [f"{failure_type}={k}" for k in failure_data['value_counts'].keys()]
                    
                    fig.add_trace(
                        go.Pie(values=values, labels=labels, name=failure_type),
                        row=row, col=col
                    )
        
        fig.update_layout(height=400 * rows, showlegend=True)
        st.plotly_chart(fig, use_container_width=True)
        
        # Failure rates table
        st.subheader("T·ªâ l·ªá failure theo t·ª´ng lo·∫°i")
        failure_rates = []
        for failure_type in available_types:
            if failure_type in failure_analysis:
                failure_data = failure_analysis[failure_type]
                if failure_data['failure_rate'] is not None:
                    failure_rates.append({
                        'Lo·∫°i Failure': failure_type,
                        'T·ªâ l·ªá': f"{failure_data['failure_rate']:.4f}",
                        'T·ªïng s·ªë failure': failure_data['total_failures']
                    })
        
        if failure_rates:
            rates_df = pd.DataFrame(failure_rates)
            st.dataframe(rates_df, use_container_width=True)

def advanced_analysis_page():
    st.markdown('<h2 class="section-header">Ph√¢n t√≠ch n√¢ng cao</h2>', unsafe_allow_html=True)
    
    if st.session_state.data is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i l√™n d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    
    data_options = ["D·ªØ li·ªáu g·ªëc"]
    if st.session_state.cleaned_data is not None:
        data_options.append("D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch")
    
    data_choice = st.radio("Ch·ªçn d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch:", data_options)
    df = st.session_state.cleaned_data if data_choice == "D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch" else st.session_state.data
    
    analysis_type = st.selectbox(
        "Ch·ªçn lo·∫°i ph√¢n t√≠ch:",
        ["Ph√¢n t√≠ch Outlier chi ti·∫øt", "Ph√¢n t√≠ch m·ªëi quan h·ªá bi·∫øn", "Th·ªëng k√™ m√¥ t·∫£ n√¢ng cao"]
    )
    
    if analysis_type == "Ph√¢n t√≠ch Outlier chi ti·∫øt":
        st.subheader("Ph√¢n t√≠ch Outlier chi ti·∫øt")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        # Remove binary columns
        numeric_cols = [col for col in numeric_cols if df[col].nunique() > 2]
        
        if numeric_cols:
            selected_col = st.selectbox("Ch·ªçn c·ªôt ƒë·ªÉ ph√¢n t√≠ch outlier:", numeric_cols)
            
            if selected_col:
                col_data = df[selected_col].dropna()
                
                # Calculate outlier bounds
                Q1 = col_data.quantile(0.25)
                Q3 = col_data.quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = col_data[(col_data < lower_bound) | (col_data > upper_bound)]
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("T·ªïng s·ªë outlier", len(outliers))
                with col2:
                    st.metric("T·ªâ l·ªá outlier", f"{len(outliers)/len(col_data)*100:.2f}%")
                with col3:
                    st.metric("Gi√° tr·ªã b√¨nh th∆∞·ªùng", len(col_data) - len(outliers))
                
                # Outlier visualization
                fig = go.Figure()
                
                # Box plot
                fig.add_trace(go.Box(y=col_data, name="Box Plot", boxpoints="outliers"))
                
                fig.update_layout(
                    title=f"Outlier Analysis - {selected_col}",
                    yaxis_title=selected_col
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Show outlier values
                if len(outliers) > 0:
                    st.subheader("Gi√° tr·ªã outlier:")
                    outlier_df = pd.DataFrame({
                        'Index': outliers.index,
                        'Value': outliers.values
                    })
                    st.dataframe(outlier_df.head(20))
    
    elif analysis_type == "Ph√¢n t√≠ch m·ªëi quan h·ªá bi·∫øn":
        st.subheader("Ph√¢n t√≠ch m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) >= 2:
            col1 = st.selectbox("Ch·ªçn bi·∫øn X:", numeric_cols)
            col2 = st.selectbox("Ch·ªçn bi·∫øn Y:", [c for c in numeric_cols if c != col1])
            
            if col1 and col2:
                # Scatter plot with correlation
                corr_coef = df[col1].corr(df[col2])
                
                fig = px.scatter(
                    df, x=col1, y=col2,
                    title=f"M·ªëi quan h·ªá gi·ªØa {col1} v√† {col2}<br>Correlation: {corr_coef:.3f}",
                    trendline="ols"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Additional statistics
                st.subheader("Th·ªëng k√™ m·ªëi quan h·ªá:")
                st.write(f"**H·ªá s·ªë t∆∞∆°ng quan Pearson:** {corr_coef:.4f}")
                
                if abs(corr_coef) > 0.7:
                    st.success("üîµ T∆∞∆°ng quan m·∫°nh")
                elif abs(corr_coef) > 0.5:
                    st.info("üîµ T∆∞∆°ng quan v·ª´a")
                elif abs(corr_coef) > 0.3:
                    st.warning("üü° T∆∞∆°ng quan y·∫øu")
                else:
                    st.error("üî¥ Kh√¥ng c√≥ t∆∞∆°ng quan ƒë√°ng k·ªÉ")
    
    elif analysis_type == "Th·ªëng k√™ m√¥ t·∫£ n√¢ng cao":
        st.subheader("Th·ªëng k√™ m√¥ t·∫£ n√¢ng cao")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            selected_cols = st.multiselect(
                "Ch·ªçn c√°c c·ªôt ƒë·ªÉ ph√¢n t√≠ch:",
                numeric_cols,
                default=numeric_cols[:5] if len(numeric_cols) > 5 else numeric_cols
            )
            
            if selected_cols:
                # Advanced statistics
                advanced_stats = []
                for col in selected_cols:
                    col_data = df[col].dropna()
                    if len(col_data) > 0:
                        stats_dict = {
                            'Column': col,
                            'Count': len(col_data),
                            'Mean': col_data.mean(),
                            'Median': col_data.median(),
                            'Std': col_data.std(),
                            'Skewness': col_data.skew(),
                            'Kurtosis': col_data.kurtosis(),
                            'Min': col_data.min(),
                            'Max': col_data.max(),
                            'Range': col_data.max() - col_data.min(),
                            'IQR': col_data.quantile(0.75) - col_data.quantile(0.25),
                            'CV': col_data.std() / col_data.mean() * 100 if col_data.mean() != 0 else 0
                        }
                        advanced_stats.append(stats_dict)
                
                if advanced_stats:
                    stats_df = pd.DataFrame(advanced_stats)
                    st.dataframe(stats_df, use_container_width=True)
                    
                    # Distribution comparison
                    st.subheader("So s√°nh ph√¢n ph·ªëi")
                    
                    # Create normalized histograms
                    fig = go.Figure()
                    
                    for col in selected_cols:
                        col_data = df[col].dropna()
                        if len(col_data) > 0:
                            fig.add_trace(go.Histogram(
                                x=col_data,
                                name=col,
                                opacity=0.7,
                                histnorm='probability density'
                            ))
                    
                    fig.update_layout(
                        title="So s√°nh ph√¢n ph·ªëi c√°c bi·∫øn",
                        xaxis_title="Gi√° tr·ªã",
                        yaxis_title="M·∫≠t ƒë·ªô x√°c su·∫•t",
                        barmode='overlay'
                    )
                    st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()