import streamlit as st
import pandas as pd
from utils.data_cleaner import DataCleaner
from utils.visualizer import Visualizer

st.set_page_config(page_title="LÃ m Sáº¡ch Dá»¯ Liá»‡u", page_icon="ğŸ§¹", layout="wide")

def main():
    st.title("ğŸ§¹ LÃ m Sáº¡ch Dá»¯ Liá»‡u TÆ°Æ¡ng TÃ¡c")
    st.markdown("Ãp dá»¥ng cÃ¡c ká»¹ thuáº­t lÃ m sáº¡ch dá»¯ liá»‡u khÃ¡c nhau Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»¯ liá»‡u.")
    
    # Check if we have data to clean
    if st.session_state.dirty_data is None:
        st.warning("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u báº©n. Vui lÃ²ng táº¡o dá»¯ liá»‡u báº©n trÆ°á»›c.")
        if st.button("ğŸ—‚ï¸ Äi Äáº¿n Táº¡o Dá»¯ Liá»‡u Báº©n"):
            st.switch_page("pages/3_Generate_Dirty_Data.py")
        st.stop()
    
    cleaner = DataCleaner()
    visualizer = Visualizer()
    
    # Initialize cleaned data if not exists
    if st.session_state.cleaned_data is None:
        st.session_state.cleaned_data = st.session_state.dirty_data.copy()
    
    df_dirty = st.session_state.dirty_data
    df_cleaned = st.session_state.cleaned_data
    
    # Show current status
    st.subheader("ğŸ“Š Tráº¡ng ThÃ¡i LÃ m Sáº¡ch Hiá»‡n Táº¡i")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("GiÃ¡ Trá»‹ Thiáº¿u Gá»‘c", df_dirty.isnull().sum().sum())
    with col2:
        st.metric("GiÃ¡ Trá»‹ Thiáº¿u Hiá»‡n Táº¡i", df_cleaned.isnull().sum().sum())
        improvement = df_dirty.isnull().sum().sum() - df_cleaned.isnull().sum().sum()
        st.metric("Cáº£i Thiá»‡n", improvement, delta=improvement)
    with col3:
        dirty_quality = st.session_state.data_processor.get_data_quality_score(df_dirty)
        cleaned_quality = st.session_state.data_processor.get_data_quality_score(df_cleaned)
        st.metric("Äiá»ƒm Cháº¥t LÆ°á»£ng", f"{cleaned_quality['overall']:.1f}/100", 
                 delta=f"{cleaned_quality['overall'] - dirty_quality['overall']:.1f}")
    
    # Cleaning operations
    st.subheader("ğŸ› ï¸ CÃ¡c Thao TÃ¡c LÃ m Sáº¡ch Dá»¯ Liá»‡u")
    
    # Create tabs for different cleaning operations
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "GiÃ¡ Trá»‹ Thiáº¿u", "GiÃ¡ Trá»‹ Ngoáº¡i Lai", "Dá»¯ Liá»‡u PhÃ¢n Loáº¡i", "Chuáº©n HÃ³a & MÃ£ HÃ³a", "NÃ¢ng Cao"
    ])
    
    with tab1:
        st.markdown("### ğŸ•³ï¸ Xá»­ LÃ½ GiÃ¡ Trá»‹ Thiáº¿u")
        
        # Show missing values summary
        missing_summary = df_cleaned.isnull().sum()
        missing_cols = missing_summary[missing_summary > 0].index.tolist()
        
        if missing_cols:
            # Select columns to handle
            selected_cols = st.multiselect(
                "Chá»n cÃ¡c cá»™t Ä‘á»ƒ xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u:",
                missing_cols,
                default=missing_cols
            )
            
            if selected_cols:
                # Choose strategy
                strategy = st.selectbox(
                    "Chá»n chiáº¿n lÆ°á»£c xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u:",
                    ["mean", "median", "mode", "forward_fill", "backward_fill", 
                     "interpolate", "knn", "constant", "custom", "drop_rows", "drop_columns"]
                )
                
                # Additional parameters for some strategies
                custom_value = None
                if strategy == "custom":
                    custom_value = st.text_input("Enter custom value:", value="Unknown")
                elif strategy == "constant":
                    custom_value = st.text_input("Enter constant value:", value="Missing")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ§¹ Ãp Dá»¥ng Xá»­ LÃ½ GiÃ¡ Trá»‹ Thiáº¿u", type="primary"):
                        try:
                            df_cleaned = cleaner.handle_missing_values(
                                df_cleaned, strategy=strategy, columns=selected_cols, 
                                custom_value=custom_value
                            )
                            st.session_state.cleaned_data = df_cleaned
                            st.success(f"âœ… Applied {strategy} strategy to {len(selected_cols)} columns")
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ Error applying strategy: {str(e)}")
                
                with col2:
                    if st.button("ğŸ‘ï¸ Xem TrÆ°á»›c Thay Äá»•i"):
                        try:
                            preview_df = cleaner.handle_missing_values(
                                df_cleaned, strategy=strategy, columns=selected_cols,
                                custom_value=custom_value
                            )
                            
                            # Show before/after comparison
                            st.markdown("**Before:**")
                            st.write(f"Missing values: {df_cleaned[selected_cols].isnull().sum().sum()}")
                            st.markdown("**After:**")
                            st.write(f"Missing values: {preview_df[selected_cols].isnull().sum().sum()}")
                            
                        except Exception as e:
                            st.error(f"âŒ Error previewing: {str(e)}")
            
            # Visualize missing values
            if len(missing_cols) > 0:
                st.markdown("### ğŸ“Š Missing Values Visualization")
                fig = visualizer.plot_missing_values_summary(df_cleaned)
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.success("ğŸ‰ KhÃ´ng phÃ¡t hiá»‡n giÃ¡ trá»‹ thiáº¿u nÃ o trong bá»™ dá»¯ liá»‡u hiá»‡n táº¡i!")
    
    with tab2:
        st.markdown("### ğŸ“ˆ Handle Outliers")
        
        numeric_cols = df_cleaned.select_dtypes(include=['number']).columns.tolist()
        
        if numeric_cols:
            # Outlier detection first
            outlier_method = st.selectbox(
                "Select outlier detection method:",
                ["iqr", "zscore", "isolation_forest"]
            )
            
            outliers = st.session_state.data_processor.detect_outliers(
                df_cleaned, method=outlier_method
            )
            
            # Show outlier summary
            outlier_data = []
            for col, info in outliers.items():
                if info['count'] > 0:
                    outlier_data.append({
                        'Column': col,
                        'Outliers': info['count'],
                        'Percentage': f"{info['percentage']:.2f}%"
                    })
            
            if outlier_data:
                outlier_df = pd.DataFrame(outlier_data)
                st.dataframe(outlier_df, use_container_width=True)
                
                # Select columns for outlier removal
                outlier_cols = [row['Column'] for row in outlier_data]
                selected_outlier_cols = st.multiselect(
                    "Select columns to remove outliers:",
                    outlier_cols,
                    default=outlier_cols
                )
                
                if selected_outlier_cols:
                    threshold = st.slider(
                        "Threshold (for IQR/Z-score methods):",
                        min_value=1.0,
                        max_value=3.0,
                        value=1.5,
                        step=0.1
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("ğŸ§¹ Remove Outliers", type="primary"):
                            try:
                                df_cleaned = cleaner.remove_outliers(
                                    df_cleaned, method=outlier_method, 
                                    columns=selected_outlier_cols, threshold=threshold
                                )
                                st.session_state.cleaned_data = df_cleaned
                                st.success(f"âœ… Removed outliers from {len(selected_outlier_cols)} columns")
                                st.rerun()
                            except Exception as e:
                                st.error(f"âŒ Error removing outliers: {str(e)}")
                    
                    with col2:
                        if st.button("ğŸ‘ï¸ Preview Outlier Removal"):
                            try:
                                preview_df = cleaner.remove_outliers(
                                    df_cleaned, method=outlier_method,
                                    columns=selected_outlier_cols, threshold=threshold
                                )
                                st.write(f"Rows before: {len(df_cleaned)}")
                                st.write(f"Rows after: {len(preview_df)}")
                                st.write(f"Rows removed: {len(df_cleaned) - len(preview_df)}")
                            except Exception as e:
                                st.error(f"âŒ Error previewing: {str(e)}")
                
                # Visualize outliers
                st.markdown("### ğŸ“Š Outliers Visualization")
                fig = visualizer.plot_outliers_boxplot(df_cleaned, selected_outlier_cols if 'selected_outlier_cols' in locals() else outlier_cols[:3])
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.success("ğŸ‰ No outliers detected in the current dataset!")
        else:
            st.info("No numeric columns available for outlier detection.")
    
    with tab3:
        st.markdown("### ğŸ”¤ Standardize Categorical Data")
        
        categorical_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()
        
        if categorical_cols:
            selected_cat_cols = st.multiselect(
                "Select categorical columns to standardize:",
                categorical_cols,
                default=categorical_cols
            )
            
            if selected_cat_cols:
                # Show current categorical data issues
                for col in selected_cat_cols:
                    with st.expander(f"ğŸ“Š Analysis for {col}"):
                        unique_values = df_cleaned[col].value_counts().head(20)
                        st.write(f"Unique values: {df_cleaned[col].nunique()}")
                        st.write("Top values:")
                        st.dataframe(unique_values, use_container_width=True)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ§¹ Standardize Categorical Data", type="primary"):
                        try:
                            df_cleaned = cleaner.standardize_categorical_data(
                                df_cleaned, columns=selected_cat_cols
                            )
                            st.session_state.cleaned_data = df_cleaned
                            st.success(f"âœ… Standardized {len(selected_cat_cols)} categorical columns")
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ Error standardizing: {str(e)}")
                
                with col2:
                    if st.button("ğŸ‘ï¸ Preview Standardization"):
                        try:
                            preview_df = cleaner.standardize_categorical_data(
                                df_cleaned, columns=selected_cat_cols
                            )
                            
                            for col in selected_cat_cols[:2]:  # Show first 2 columns
                                st.write(f"**{col}** - Unique values before: {df_cleaned[col].nunique()}, after: {preview_df[col].nunique()}")
                                
                        except Exception as e:
                            st.error(f"âŒ Error previewing: {str(e)}")
        else:
            st.info("No categorical columns available for standardization.")
    
    with tab4:
        st.markdown("### âš–ï¸ Scaling and Encoding")
        
        # Scaling section
        st.markdown("#### Numeric Feature Scaling")
        numeric_cols = df_cleaned.select_dtypes(include=['number']).columns.tolist()
        
        if numeric_cols:
            selected_scale_cols = st.multiselect(
                "Select numeric columns to scale:",
                numeric_cols,
                help="Scaling normalizes the range of features"
            )
            
            if selected_scale_cols:
                scale_method = st.selectbox(
                    "Select scaling method:",
                    ["standard", "minmax", "robust"]
                )
                
                if st.button("âš–ï¸ Apply Scaling", type="primary"):
                    try:
                        df_cleaned = cleaner.scale_numeric_features(
                            df_cleaned, method=scale_method, columns=selected_scale_cols
                        )
                        st.session_state.cleaned_data = df_cleaned
                        st.success(f"âœ… Applied {scale_method} scaling to {len(selected_scale_cols)} columns")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ Error scaling: {str(e)}")
        
        # Encoding section
        st.markdown("#### Categorical Variable Encoding")
        categorical_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()
        
        if categorical_cols:
            selected_encode_cols = st.multiselect(
                "Select categorical columns to encode:",
                categorical_cols,
                help="Encoding converts categorical variables to numeric"
            )
            
            if selected_encode_cols:
                encode_method = st.selectbox(
                    "Select encoding method:",
                    ["label", "onehot", "frequency"]
                )
                
                if st.button("ğŸ”¢ Apply Encoding", type="primary"):
                    try:
                        df_cleaned = cleaner.encode_categorical_variables(
                            df_cleaned, method=encode_method, columns=selected_encode_cols
                        )
                        st.session_state.cleaned_data = df_cleaned
                        st.success(f"âœ… Applied {encode_method} encoding to {len(selected_encode_cols)} columns")
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ Error encoding: {str(e)}")
    
    with tab5:
        st.markdown("### ğŸš€ Advanced Operations")
        
        # Remove duplicates
        st.markdown("#### Remove Duplicate Rows")
        duplicate_count = df_cleaned.duplicated().sum()
        st.write(f"Duplicate rows found: {duplicate_count}")
        
        if duplicate_count > 0:
            keep_option = st.selectbox("Keep which duplicate:", ["first", "last", "none"])
            
            if st.button("ğŸ—‘ï¸ Remove Duplicates", type="primary"):
                try:
                    df_cleaned = cleaner.remove_duplicates(df_cleaned, keep=keep_option)
                    st.session_state.cleaned_data = df_cleaned
                    st.success(f"âœ… Removed {duplicate_count} duplicate rows")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ Error removing duplicates: {str(e)}")
        else:
            st.success("ğŸ‰ No duplicate rows found!")
        
        # Data type detection and fixing
        st.markdown("#### Automatic Data Type Detection")
        if st.button("ğŸ” Detect and Fix Data Types"):
            try:
                df_cleaned = cleaner.detect_and_fix_data_types(df_cleaned)
                st.session_state.cleaned_data = df_cleaned
                st.success("âœ… Automatically detected and fixed data types")
                st.rerun()
            except Exception as e:
                st.error(f"âŒ Error fixing data types: {str(e)}")
        
        # Reset to original dirty data
        st.markdown("#### Reset Operations")
        if st.button("ğŸ”„ Reset to Original Dirty Data", type="secondary"):
            st.session_state.cleaned_data = st.session_state.dirty_data.copy()
            st.success("âœ… Reset to original dirty data")
            st.rerun()
    
    # Show cleaning summary
    st.markdown("---")
    st.subheader("ğŸ“‹ Cleaning Summary")
    
    # Generate cleaning summary
    summary = cleaner.get_cleaning_summary(df_dirty, df_cleaned)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Rows Removed", summary['rows_removed'])
    with col2:
        st.metric("Columns Changed", summary['columns_removed'])
    with col3:
        st.metric("Missing Values Handled", summary['missing_values_handled']['reduction'])
    with col4:
        st.metric("New Columns Added", len(summary['new_columns_added']))
    
    # Data type changes
    if summary['data_types_changed']:
        with st.expander("ğŸ“Š Data Type Changes"):
            for col, change in summary['data_types_changed'].items():
                st.write(f"**{col}**: {change['from']} â†’ {change['to']}")
    
    # Final comparison visualization
    st.subheader("ğŸ“Š Before vs After Comparison")
    
    quality_dirty = st.session_state.data_processor.get_data_quality_score(df_dirty)
    quality_cleaned = st.session_state.data_processor.get_data_quality_score(df_cleaned)
    
    fig = visualizer.plot_data_quality_comparison(quality_dirty, quality_cleaned)
    st.plotly_chart(fig, use_container_width=True)
    
    # Action buttons
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("ğŸ’¾ Export Cleaned Data", use_container_width=True):
            st.switch_page("pages/5_Export_Data.py")
    
    with col2:
        if st.button("ğŸ“Š View Data Overview", use_container_width=True):
            st.switch_page("pages/2_Data_Overview.py")
    
    with col3:
        if st.button("ğŸ”„ Start Over", use_container_width=True):
            st.session_state.cleaned_data = None
            st.session_state.dirty_data = None
            st.switch_page("pages/1_Data_Upload.py")

if __name__ == "__main__":
    main()
